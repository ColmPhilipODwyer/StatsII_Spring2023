\documentclass[12pt,letterpaper]{article}
\usepackage{graphicx,textcomp}
\usepackage{natbib}
\usepackage{setspace}
\usepackage{fullpage}
\usepackage{color}
\usepackage[reqno]{amsmath}
\usepackage{amsthm}
\usepackage{fancyvrb}
\usepackage{amssymb,enumerate}
\usepackage[all]{xy}
\usepackage{endnotes}
\usepackage{lscape}
\newtheorem{com}{Comment}
\usepackage{float}
\usepackage{hyperref}
\newtheorem{lem} {Lemma}
\newtheorem{prop}{Proposition}
\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{cor}{Corollary}
\newtheorem{obs}{Observation}
\usepackage[compact]{titlesec}
\usepackage{dcolumn}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{multirow}
\usepackage{xcolor}
\newcolumntype{.}{D{.}{.}{-1}}
\newcolumntype{d}[1]{D{.}{.}{#1}}
\definecolor{light-gray}{gray}{0.65}
\usepackage{url}
\usepackage{listings}
\usepackage{color}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}
\lstset{style=mystyle}
\newcommand{\Sref}[1]{Section~\ref{#1}}
\newtheorem{hyp}{Hypothesis}

\title{Problem Set 2}
\date{Due: February 19, 2023}
\author{Applied Stats II}


\begin{document}
	\maketitle
	\section*{Instructions}
	\begin{itemize}
		\item Please show your work! You may lose points by simply writing in the answer. If the problem requires you to execute commands in \texttt{R}, please include the code you used to get your answers. Please also include the \texttt{.R} file that contains your code. If you are not sure if work needs to be shown for a particular problem, please ask.
		\item Your homework should be submitted electronically on GitHub in \texttt{.pdf} form.
		\item This problem set is due before 23:59 on Sunday February 19, 2023. No late assignments will be accepted.
	%	\item Total available points for this homework is 80.
	\end{itemize}

	
	%	\vspace{.25cm}
	
%\noindent In this problem set, you will run several regressions and create an add variable plot (see the lecture slides) in \texttt{R} using the \texttt{incumbents\_subset.csv} dataset. Include all of your code.

	\vspace{.25cm}
%\section*{Question 1} %(20 points)}
%\vspace{.25cm}
\noindent We're interested in what types of international environmental agreements or policies people support (\href{https://www.pnas.org/content/110/34/13763}{Bechtel and Scheve 2013)}. So, we asked 8,500 individuals whether they support a given policy, and for each participant, we vary the (1) number of countries that participate in the international agreement and (2) sanctions for not following the agreement. \\

\noindent Load in the data labeled \texttt{climateSupport.csv} on GitHub, which contains an observational study of 8,500 observations.

\begin{itemize}
	\item
	Response variable: 
	\begin{itemize}
		\item \texttt{choice}: 1 if the individual agreed with the policy; 0 if the individual did not support the policy
	\end{itemize}
	\item
	Explanatory variables: 
	\begin{itemize}
		\item
		\texttt{countries}: Number of participating countries [20 of 192; 80 of 192; 160 of 192]
		\item
		\texttt{sanctions}: Sanctions for missing emission reduction targets [None, 5\%, 15\%, and 20\% of the monthly household costs given 2\% GDP growth]
		
	\end{itemize}
	
\end{itemize}

\newpage
\noindent Please answer the following questions:

\begin{enumerate}
	\item
	Remember, we are interested in predicting the likelihood of an individual supporting a policy based on the number of countries participating and the possible sanctions for non-compliance.
	\begin{enumerate}
		\item [] Fit an additive model. Provide the summary output, the global null hypothesis, and $p$-value. Please describe the results and provide a conclusion.
		%\item
		%How many iterations did it take to find the maximum likelihood estimates?
	\end{enumerate}
	
	\begin{verbatim}
First I recode "choice" as a binary outcome variable:
		climateSupport$choice_binary <- ifelse(climateSupport$choice == "Supported", 1, 0)
		
I fit a generalised linear model with 'choice' as the outcome variable, and
'countries' and 'sanctions' as the predictor variables.

	likelihood_model1 <-glm(choice_binary ~ countries + sanctions,
		data = climateSupport)
	summary(likelihood_model1)

Here is the summary output:

Agreement Support Likelihood Model results
=============================================
Dependent variable:    
---------------------------
choice_binary       
---------------------------------------------
countries.L                0.113***          
(0.009)          

countries.Q                 -0.002           
(0.009)          

sanctions.L                -0.068***         
(0.011)          

sanctions.Q                -0.044***         
(0.011)          

sanctions.C                0.037***          
(0.011)          

Constant                   0.499***          
(0.005)          

---------------------------------------------
Observations                 8,500           
Log Likelihood            -6,062.235         
Akaike Inf. Crit.         12,136.470         
=============================================
Note:             *p<0.1; **p<0.05; ***p<0.01

Summary of results:

The intercept has a log odds value of 0.499. This suggests that individuals
have a likelihood of about 62% to support an environmental agreement which
is agreed by 20 of 192 countries, but which has no sanctions for missing
emission reduction targets (the two baseline categories).

The  coefficient estimate for 'countries.L' is positive, and highly significant
(p<0.001). This suggests that  having 80 participating countries is positively
associated with support for an agreement, compare to the baseline category of
20 countries supporting.
However, the coefficient estimate for 'countries.Q' is not statistically
significant, suggesting that an agreement having 160 countries participating
does not have a significant effect on likelihood to support an agreement,
compared to the baseline category of 20 countries supporting.

The three coefficient estimates for the three levels of sanctions are all
highly statistically significant (p<0.001). Coefficients for 'sanctions.L'
and 'sanctions.Q' are negative, whilst the coefficient for 'sanctions.C'
is positive. This suggests that the level of sanctions for missing emission
reduction targets are negatively associated with likelihood for individuals
to support an agreement at  5% and 15% sanctions, relative to the baseline
category of no sanctions, but that at 20% this effect is reversed.

In conclusion, the number of countries participating in the agreement
matters for the likelihood of individuals to support an agreement, but
only up to a point. After a certain level, additional countries'
participation do not positively effect odds of supporting an agreement.
On the other hand, higher levels of sanctions are negatively associated
with support for an agreement at 5% and 15% sanctions, although the trend
is reversed at the highest level of sanctions tested (20%).


Global NUll Hypothesis test:


First, I create the null model, with only an intercept term, which I will
test my model against:
null_model <- glm(choice_binary ~ 1, data = climateSupport)

Next, I perform the likelihood ratio test:
null_test <- anova(null_model, likelihood_model, test = "Chisq")

Here are the results:
Model 1: choice_binary ~ 1
Model 2: choice_binary ~ countries + sanctions
Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    
1      8499     2125.0                          
2      8494     2071.7  5   53.292 < 2.2e-16 ***

P < 0.05, therefore we can reject the global null hypothesis, that all of the
coefficients of the independent variables in the model are equal to zero.
Therefore, we can conclude that at least one of the coefficients in the model
is significantly different from zero, and that thre model provides an
improvement over the null model.

	\end{verbatim}
	
	\item
	If any of the explanatory variables are significant in this model, then:
	\begin{enumerate}
		\item
		For the policy in which nearly all countries participate [160 of 192], how does increasing sanctions from 5\% to 15\% change the odds that an individual will support the policy? (Interpretation of a coefficient)
		
	\begin{verbatim}	
		
		First I calculate the log odds for each of the two scenarios:
		
		log(odds) when sanctions are 5% = 0.498607 -0.067615 -0.002386 = 0.428606
		log(odds) when sanctions are 15% = 0.498607 -0.044187 -0.002386 = 0.452034
		
		Next I use the two sets of log odds to calculate the difference in odds:
		
		difference_in_odds <- exp(0.428606) - exp(0.452034)
		difference_in_odds
		Difference in odds = [1] -0.0363893
	
	\end{verbatim}		
		
%		\item
%		For the policy in which very few countries participate [20 of 192], how does increasing sanctions from 5\% to 15\% change the odds that an individual will support the policy? (Interpretation of a coefficient)
		\item
		What is the estimated probability that an individual will support a policy if there are 80 of 192 countries participating with no sanctions? 
		
		\begin{verbatim}	
		First I calculate the log odds:	
		log(odds) = 0.498607 -0.002386 = 0.496221
		
		
		Then I use the log odds to calculate the probability that an individual will
		support a policy if there are 80 countries participating with no sanctions:
		probability <- 1/(1 + exp(1)^(-0.496221))
		probability = 0.6482389
		
		\end{verbatim}		
		
		\item
		Would the answers to 2a and 2b potentially change if we included the interaction term in this model? Why? 
		\begin{itemize}
			\item Perform a test to see if including an interaction is appropriate.
		\end{itemize}
	
		\begin{verbatim}	
		It is possible that model fit could be improved by the inclusion of an
		interaction effect. When an interaction effect is included in the model,
		it introduces a new term that represents the combined effect of the two
		independent variables on the dependent variable. This new term can change
		the coefficients of the other independent variables in the model by
		enhancing or diminishing the relationship between the other independent
		variables and independent variable, depending on the nature of the interaction.
		
	
		In order to test if the inclusion of an interaction effect is appropriate in
		this case, I conduct a likelihood ratio test.
		
		Firstly, I create a model with the interaction effect included:
		likelihood_model_interaction <- glm(choice_binary ~ countries * sanctions,
		data = climateSupport)
		
		Next I calculate the deviance of both models:
		deviance_original_model <- deviance(likelihood_model)
		deviance_interaction_model <- deviance(likelihood_model_interaction)
		
		I calculate the likelihood ratio statistic:
		lr_stat <- abs(deviance_interaction_model - deviance_original_model)
		lr_stat
		# [1] 1.598523
		
		I calculate the difference in the degrees of freedom:
		df_diff <- df.residual(likelihood_model)
			- df.residual(likelihood_model_interaction)
		
		Finally, I calculate the p-value:
		p_value <- pchisq(lr_stat, df_diff, lower.tail = FALSE)
		p_value
		# [1] 0.9526835
		
		Because p>0.05, I fail to reject the null hypothesis, that the model without
		including interaction is sufficient, and that it is unnecessary to include
		an interaction effect.
		
	\end{verbatim}		
	
	\end{enumerate}
	\end{enumerate}


\end{document}
